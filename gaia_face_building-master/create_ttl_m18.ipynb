{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataName = 'm18'\n",
    "dataName2 = 'm18_f'\n",
    "parent_file = '/home/brian/facenet-master/results/parent_'+dataName+'.tab'\n",
    "video_frame_mapping = '/dvmm-filer2/projects/AIDA/data/ldc_eval_m18/LDC2019E42 \\\n",
    "_AIDA_Phase_1_Evaluation_Source_Data_V1.0/docs/masterShotBoundary.msb'\n",
    "face_img_result = '/home/brian/facenet-master/results/result_'+dataName+'.p'\n",
    "face_frame_result = '/home/brian/facenet-master/results/result_'+dataName2+'.p'\n",
    "bbox_img = '/home/brian/facenet-master/results/bbox_'+dataName+'.pickle'\n",
    "bbox_frame = '/home/brian/facenet-master/results/bbox_'+dataName2+'.pickle'\n",
    "az_obj_graph = '/home/brian/facenet-master/results/rdf_graphs_34.pkl'\n",
    "az_obj_jpg = '/home/brian/facenet-master/results/det_results_merged_34a_jpg.pkl'\n",
    "az_obj_kf = '/home/brian/facenet-master/results/det_results_merged_34b_kf.pkl'\n",
    "Lorelei_path = '/home/brian/facenet-master/LDC2018E80_LORELEI_Background_KB/data/entities.tab'\n",
    "flag_result = '/home/brian/tensorflow-retrain-sample/flag_m18_2.pickle'\n",
    "landmark_result = '/home/brian/tensorflow/models/research/delf/delf/python/examples/result_dic_m18_new.p'\n",
    "RPI_entity = '/home/brian/facenet-master/results/PT003_r1.pickle'\n",
    "input_img_path = '/home/brian/facenet-master/datasets/m18/m18/'\n",
    "outputN = 'm18_auto'\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "from multiprocessing import Pool \n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "#import visualization_utils\n",
    "import scipy.misc\n",
    "from glob import glob\n",
    "import operator\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import csv\n",
    "import lmdb\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append(\"/dvmm-filer2/projects/AIDA/alireza/tools/AIDA-Interchange-Format/python/aida_interchange\")\n",
    "sys.path.append(\"/home/brian/AIDA-Interchange-Format/python\")\n",
    "from rdflib import URIRef\n",
    "from rdflib.namespace import ClosedNamespace\n",
    "\n",
    "file1 = open('results/result_p1_50_new.txt')\n",
    "p1Set = set()\n",
    "nameSet2 = set()\n",
    "for line in file1:\n",
    "    data = line.replace('\\n','')\n",
    "    p1Set.add(data)\n",
    "    nameSet2.add(data)\n",
    "\n",
    "#print p1Set\n",
    "file1 = open('results/wikipage.txt')    \n",
    "nameDic = {}\n",
    "nameSet = set()\n",
    "\n",
    "for line in file1:\n",
    "    data = line.replace('\\n','').split('\\t')\n",
    "    \n",
    "    nameSet.add(data[0])\n",
    "    if data[1] not in p1Set:\n",
    "        nameSet2.add(data[0])\n",
    "    nameDic[data[0]] = data[1]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if dataName == 'dry3':\n",
    "child = defaultdict(list)\n",
    "file5= open(parent_file)\n",
    "i = 0\n",
    "for line in file5:\n",
    "    i+=1\n",
    "    if i ==1:\n",
    "        continue\n",
    "    data = line.split()\n",
    "    child[data[7]].append(data[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(bbox_img, 'rb') as handle:\n",
    "    bb = pickle.load(handle)\n",
    "with open(bbox_frame, 'rb') as handle:\n",
    "    bb_2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "# -*- coding: utf-8 -*-\n",
    "def isEnglish(s):\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "dupList = set()\n",
    "file2 = open('results/dupList.txt')\n",
    "for line in file2:\n",
    "    data = line.split()[0]\n",
    "    dupList.add(data)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "#print nameSet2\n",
    "VIS_ONTOLOGY2 = ClosedNamespace(\n",
    "    uri=URIRef(\"http://dbpedia.org/resource/\"),\n",
    "    terms=[str(value) for value in nameSet2]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "from aida_interchange.Bounding_Box import Bounding_Box\n",
    "from aida_interchange.aida_rdf_ontologies import SEEDLING_TYPES_NIST\n",
    "from aida_interchange.LDCTimeComponent import LDCTimeComponent, LDCTimeType\n",
    "from aida_interchange import aifutils\n",
    "\n",
    "\n",
    "\n",
    "with open(face_img_result, 'rb') as handle:\n",
    "    result = pickle.load(handle, encoding=\"latin1\")\n",
    "\n",
    "\n",
    "        \n",
    "with open(face_frame_result, 'rb') as handle:\n",
    "    result2 = pickle.load(handle, encoding=\"latin1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#if dataName == 'dry3':\n",
    "with open(az_obj_graph , 'rb') as handle:\n",
    "    (kb_dict, entity_dict, event_dict) = pickle.load(handle)\n",
    "\n",
    "with open(az_obj_jpg , 'rb') as handle:\n",
    "    OD_result = pickle.load(handle)\n",
    "\n",
    "with open(az_obj_kf , 'rb') as handle:\n",
    "    ODF_result = pickle.load(handle)\n",
    "    \n",
    "entity_dic2 = defaultdict(list)\n",
    "for x,y in entity_dict.items():\n",
    "    data = x.split('/')\n",
    "    #print data\n",
    "    entity_dic2[data[-2]].append(int(data[-1]))\n",
    "    \n",
    "#nameSet = set()\n",
    "nameList = []\n",
    "total_score = []\n",
    "scoreD_t = []\n",
    "\n",
    "\n",
    "\n",
    "category_index = {}\n",
    "index_category = {}\n",
    "i=0\n",
    "\n",
    "for name in nameSet2:\n",
    "    #print name\n",
    "    #data = name.split('/')[-1]\n",
    "    if name in dupList:\n",
    "        continue\n",
    "    #if data not in deleteSet:\n",
    "    #\tcontinue\n",
    "    #print(data)\n",
    "    i+=1\n",
    "\n",
    "    category_index[i] = {'id': i, 'name': name}\n",
    "    index_category[name] = i\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "#terms=[str(value) for value in nameSet2]\n",
    "#print terms\n",
    "clusterDic = {}\n",
    "\n",
    "#if dataName == 'dry3':\n",
    "file1 = open(video_frame_mapping)\n",
    "videoDic = {}\n",
    "for line in file1:\n",
    "    data = line.split()\n",
    "    videoDic[data[0]] = data[1].split('_')[0]\n",
    "    \n",
    "#print videoDic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index_f = {}\n",
    "index_category_f = {}\n",
    "i=0\n",
    "nameSet_c = set()\n",
    "retrain_label = 'results/retrained_labels2.txt'\n",
    "file_c = open(retrain_label)\n",
    "for line in file_c:\n",
    "    data = line.replace('\\n','')\n",
    "    #print data\n",
    "    if isEnglish(data):\n",
    "        nameSet_c.add(data)\n",
    "    \n",
    "for name in nameSet_c:\n",
    "    \n",
    "\n",
    "    i+=1\n",
    "\n",
    "    category_index_f[i] = {'id': i, 'name': name}\n",
    "    index_category_f[name.replace(' ','_')] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(index_category_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_dic2 = defaultdict(list)\n",
    "for x,y in entity_dict.items():\n",
    "    data = x.split('/')\n",
    "    #print data\n",
    "    entity_dic2[data[-2]].append(int(data[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#from pprint import pprint\n",
    "\n",
    "with open('results/freebase_links_f2w.json') as f:\n",
    "    data = json.load(f)\n",
    "free = {}\n",
    "for x, y in data.items():\n",
    "    free[y] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "from collections import defaultdict\n",
    "id2Name = defaultdict(list)\n",
    "name2ID = {}\n",
    "file1 = open(Lorelei_path)\n",
    "for line in file1:\n",
    "    data = line.split('\\t')\n",
    "    i+=1\n",
    "    #print data\n",
    "    #if i == 10:\n",
    "    #    break\n",
    "    if data[1] == 'PER':\n",
    "        #print line\n",
    "        id2Name[data[2]].append(data[3].lower())\n",
    "        name2ID[data[3].lower()] = data[2]\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#with open('tempname2ID.pickle', 'rb') as handle:\n",
    "#    name2ID = pickle.load(handle)\n",
    "    \n",
    "    \n",
    "VIS_ONTOLOGY_L = ClosedNamespace(\n",
    "    uri=URIRef(\"http://dbpedia.org/resource/\"),\n",
    "    terms=[str(value).replace(' ','_').replace('\"','') for value in name2ID]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(flag_result, 'rb') as handle:\n",
    "    flag_dict_s = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(landmark_result, 'rb') as handle:\n",
    "    landmark_dict2 = pickle.load(handle, encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "landmark_dict = {}\n",
    "for x,y in landmark_dict2.items():\n",
    "    landmark_dict[x] = y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 0, 'Supreme_Court_of_the_United_States_building': 11, 'Red_Square_Building': 2, 'Trade_Unions_Building_in_Odessa_building': 1, 'Pagan_Kingdom_Building': 5, 'Empire_State_Building': 14, 'Place_de_la_Concorde': 7, 'Spasskaya_Tower': 8, 'Ministry_of_Foreign_Affairs_of_Ukraine_building': 10, 'Buckingham_Palace': 9, 'Maidan_Nezalezhnosti': 6, 'European_Parliament_building': 3, 'US_State_Capitol': 4, 'Eiffel_Tower': 12, 'Edificio_MetrÃ³polis,_Madrid': 13}\n"
     ]
    }
   ],
   "source": [
    "landmark_id = {}\n",
    "landmarkSet = set()\n",
    "count=0\n",
    "for x,y in landmark_dict.items():\n",
    "    #print x,y\n",
    "    if y not in landmarkSet:\n",
    "        landmarkSet.add(y)\n",
    "        landmark_id[y] = count\n",
    "        count+=1\n",
    "print(landmark_id)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building_dry = ['IC0011UWP','IC0011VOR','IC0011WXU','IC0011XEN','IC0011XEO','IC0014YXH','IC0014ZPU']\n",
    "#nameSet_b =set()\n",
    "#nameSet_b.add('Maidan_Nezalezhnosti')\n",
    "VIS_ONTOLOGY_b = ClosedNamespace(\n",
    "    uri=URIRef(\"http://dbpedia.org/resource/\"),\n",
    "    terms=[str(value) for value,_ in landmarkSet]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://dbpedia.org/resource/vladimir_pesevski\n"
     ]
    }
   ],
   "source": [
    "print (VIS_ONTOLOGY_L.term('vladimir_pesevski'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print ID2name[5601538]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(RPI_entity, 'rb') as handle:\n",
    "    RPI = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))\n",
    "\n",
    "AIDA_PROGRAM_ONTOLOGY2 = ClosedNamespace(\n",
    "    #uri=URIRef(\"http://darpa.mil/ontologies/SeedlingOntology/\"),\n",
    "    uri=URIRef(\"https://tac.nist.gov/tracks/SM-KBP/2019/ontologies/LDCOntology#\"),\n",
    "    \n",
    "\n",
    "    #uri=URIRef(\"http://www.w3.org/2000/01/rdf-schema#\"),\n",
    "    \n",
    "    #uri=URIRef(\"http://rdf.freebase.com/ns/\"),\n",
    "    terms=['PER'])\n",
    "\n",
    "AIDA_PROGRAM_ONTOLOGY_b = ClosedNamespace(\n",
    "    #uri=URIRef(\"http://darpa.mil/ontologies/SeedlingOntology/\"),\n",
    "    uri=URIRef(\"https://tac.nist.gov/tracks/SM-KBP/2019/ontologies/LDCOntology#\"),\n",
    "    \n",
    "\n",
    "    #uri=URIRef(\"http://www.w3.org/2000/01/rdf-schema#\"),\n",
    "    \n",
    "    #uri=URIRef(\"http://rdf.freebase.com/ns/\"),\n",
    "    terms=['FAC'])\n",
    "\n",
    "AIDA_PROGRAM_ONTOLOGY_G = ClosedNamespace(\n",
    "    #uri=URIRef(\"http://darpa.mil/ontologies/SeedlingOntology/\"),\n",
    "    uri=URIRef(\"https://tac.nist.gov/tracks/SM-KBP/2019/ontologies/LDCOntology#\"),\n",
    "    \n",
    "\n",
    "    #uri=URIRef(\"http://www.w3.org/2000/01/rdf-schema#\"),\n",
    "    \n",
    "    #uri=URIRef(\"http://rdf.freebase.com/ns/\"),\n",
    "    terms=['GPE'])\n",
    "\n",
    "\n",
    "AIDA_PROGRAM_ONTOLOGY_A = ClosedNamespace(\n",
    "    #uri=URIRef(\"http://darpa.mil/ontologies/SeedlingOntology/\"),\n",
    "    uri=URIRef(\"https://tac.nist.gov/tracks/SM-KBP/2019/ontologies/LDCOntology#\"),\n",
    "    \n",
    "\n",
    "    #uri=URIRef(\"http://www.w3.org/2000/01/rdf-schema#\"),\n",
    "    \n",
    "    #uri=URIRef(\"http://rdf.freebase.com/ns/\"),\n",
    "    terms=['GeneralAffiliation.ArtifactPoliticalOrganizationReligiousAffiliation.NationalityCitizen', \\\n",
    "          'GeneralAffiliation.ArtifactPoliticalOrganizationReligiousAffiliation.NationalityCitizen_Artifact', \\\n",
    "          'GeneralAffiliation.ArtifactPoliticalOrganizationReligiousAffiliation.NationalityCitizen_Nationality'])\n",
    "    #terms=['Entity'])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    #iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    iou = interArea / float(boxBArea)\n",
    "\n",
    "    # return the intersection over union value\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arsen avakov\n",
      "petro poroshenko\n",
      "philip hammond\n",
      "arsen avakov\n",
      "petro poroshenko\n",
      "petro poroshenko\n",
      "petro poroshenko\n",
      "frank-walter steinmeier\n",
      "petro poroshenko\n",
      "narendra modi\n",
      "petro poroshenko\n",
      "arsen avakov\n",
      "narendra modi\n",
      "petro poroshenko\n",
      "petro poroshenko\n",
      "arseniy yatsenyuk\n",
      "narendra modi\n",
      "petro poroshenko\n",
      "petro poroshenko\n",
      "arsen avakov\n",
      "oleksandr turchynov\n",
      "arsen avakov\n",
      "narendra modi\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import multiprocessing as mp\n",
    "from scipy import spatial\n",
    "\n",
    "docNum = 0\n",
    "\n",
    "g_dic = {}\n",
    "entityDic ={}\n",
    "entityDic_b = {}\n",
    "nameCount2 = 0\n",
    "chi_set = set()\n",
    "parent_set = set()\n",
    "person_set = set()\n",
    "total_key = set()\n",
    "doc_N = set()\n",
    "img_N = set()\n",
    "clusterDic_b = {}\n",
    "#\n",
    "kb_dict_bf = {}\n",
    "\n",
    "#for parent, chi in child.items():\n",
    "    \n",
    "    #print parent\n",
    "#    docNum+=1\n",
    "    #(parent, chi) = chi_2\n",
    "    \n",
    "\n",
    "def transferAIF(parent):\n",
    "    chi = child[parent]\n",
    "    \n",
    "    if parent in kb_dict.keys():\n",
    "        g = kb_dict[parent]\n",
    "\n",
    "    else:\n",
    "        g = aifutils.make_graph()\n",
    "\n",
    "    \n",
    "    entityDic_c = {}\n",
    "    country_set_r = set()\n",
    "    for img_id in chi:\n",
    "        if img_id in flag_dict_s.keys():\n",
    "            country_set_r.add(flag_dict_s[img_id])\n",
    "    #=============== Flag ===========\n",
    "\n",
    "    sys = aifutils.make_system_with_uri(g, \"http://www.columbia.edu/AIDA/DVMM/Systems/Flag/Inception_v4\")\n",
    "    for key, value in index_category_f.items():\n",
    "        if key not in country_set_r:\n",
    "            continue\n",
    "        key = key.replace(' ','_')\n",
    "        name = \"http://www.columbia.edu/AIDA/DVMM/Entities/Country/\"+str(value)+'/'+key\n",
    "        entity = aifutils.make_entity(g, name, sys)\n",
    "        entityDic_c[key] = entity\n",
    "        #print \"parent \"+ parent\n",
    "        type_assertion = aifutils.mark_type(g, \\\n",
    "            \"http://www.columbia.edu/AIDA/DVMM/TypeAssertion/Country/\"\\\n",
    "            +str(value)+'/'+key, entity, AIDA_PROGRAM_ONTOLOGY_G.term('GPE'), sys, 1)\n",
    "    for img_id in chi:\n",
    "        if img_id in flag_dict_s.keys():\n",
    "            #print \"imgID \"+img_id\n",
    "            flag_label = ['/m/07cmd','/m/0dzct','/m/03bt1vf','/m/01g317','/m/04yx4','/m/01prls','/m/07yv9','/m/03120']\n",
    "            key = img_id\n",
    "            if key in OD_result.keys():\n",
    "                for n in range(len(OD_result[key])):\n",
    "                    eid = \"http://www.columbia.edu/AIDA/DVMM/Entities/ObjectDetection/RUN00010/JPG/\"+key+\"/\"+str(n)\n",
    "                    #print OD_result[key][n]['label']\n",
    "                    if OD_result[key][n]['label'] in flag_label:\n",
    "                        #print OD_result[key][n]['label']\n",
    "                        eid = \"http://www.columbia.edu/AIDA/DVMM/Entities/ObjectDetection/RUN00010/JPG/\"+key+\"/\"+str(n)\n",
    "                        relation_entity = aifutils.make_relation(g, \"http://www.columbia.edu/AIDA/DVMM/Relaion/Flag/\"+\\\n",
    "                                                                key+\"/\"+str(n), sys)\n",
    "                        #APORA = 'GeneralAffiliation.ArtifactPoliticalOrganizationReligiousAffiliation'\n",
    "                        score = 1\n",
    "                        type_assertion = aifutils.mark_type(g, \"http://www.columbia.edu/AIDA/DVMM/TypeAssertion/Flag/\"+key+\"/\"+str(n), \\\n",
    "                            relation_entity, AIDA_PROGRAM_ONTOLOGY_A['GeneralAffiliation.ArtifactPoliticalOrganizationReligiousAffiliation.NationalityCitizen'], \\\n",
    "                                                    sys, score)\n",
    "                        boxA = OD_result[key][n]['bbox']\n",
    "                        bb2 = Bounding_Box((boxA[0],boxA[1]),(boxA[2],boxA[3]))\n",
    "                        score = 1\n",
    "                        justif = aifutils.mark_image_justification(g, [relation_entity, \\\n",
    "                                                           type_assertion], key, bb2, sys, score)\n",
    "                        aifutils.add_source_document_to_justification(g, justif, parent)\n",
    "                        aifutils.mark_informative_justification(g, relation_entity, justif)\n",
    "                        score = 1\n",
    "                        if eid in entity_dict.keys():\n",
    "                            art_argument = aifutils.mark_as_argument(g, relation_entity, \\\n",
    "                            AIDA_PROGRAM_ONTOLOGY_A['GeneralAffiliation.ArtifactPoliticalOrganizationReligiousAffiliation.NationalityCitizen_Artifact'], \\\n",
    "                                                                entity_dict[eid], sys, score)\n",
    "                            score = 1\n",
    "                            justif = aifutils.mark_image_justification(g, [relation_entity, \\\n",
    "                                                               art_argument], key, bb2, sys, score)\n",
    "                            aifutils.add_source_document_to_justification(g, justif, parent)\n",
    "                            aifutils.mark_informative_justification(g, relation_entity, justif)\n",
    "                        score = 1\n",
    "                        nation_argument = aifutils.mark_as_argument(g, relation_entity, \\\n",
    "                            AIDA_PROGRAM_ONTOLOGY_A['GeneralAffiliation.ArtifactPoliticalOrganizationReligiousAffiliation.NationalityCitizen_Nationality'], \\\n",
    "                                                                    entityDic_c[flag_dict_s[img_id]], \\\n",
    "                                                                    sys, score)\n",
    "                        score = 1\n",
    "                        justif = aifutils.mark_image_justification(g, [relation_entity, \\\n",
    "                                                               nation_argument], key, bb2, sys, score)\n",
    "                        aifutils.add_source_document_to_justification(g, justif, parent)\n",
    "                        aifutils.mark_informative_justification(g, relation_entity, justif)\n",
    "                        \n",
    "                    if OD_result[key][n]['label'] == '/m/03120':\n",
    "                        #print flag_dict_s[img_id]\n",
    "                        boxA = OD_result[key][n]['bbox']\n",
    "                        bb2 = Bounding_Box((boxA[0],boxA[1]),(boxA[2],boxA[3]))\n",
    "                        type_assertion = aifutils.mark_type(g, \\\n",
    "                        \"http://www.columbia.edu/AIDA/DVMM/TypeAssertion/Country/RUN00010/JPG/\"+\\\n",
    "                            str(key)+'/'+str(n), entityDic_c[flag_dict_s[img_id]], AIDA_PROGRAM_ONTOLOGY_G.term('GPE'), sys, 1)\n",
    "                        score = 1\n",
    "                        justif = aifutils.mark_image_justification(g, [entityDic_c[flag_dict_s[img_id]], type_assertion], \\\n",
    "                                                                   key, bb2, sys, score)\n",
    "                        aifutils.add_source_document_to_justification(g, justif, parent)\n",
    "                        aifutils.mark_informative_justification(g, entityDic_c[flag_dict_s[img_id]], justif)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #break\n",
    "    #=============== landmark ==========\n",
    "    sys = aifutils.make_system_with_uri(g, \"http://www.columbia.edu/AIDA/DVMM/Systems/Landmark/Delf\")\n",
    "    #building\n",
    "    has_land = 0\n",
    "    landmark_name_set = set()\n",
    "    for imageN in chi:\n",
    "        if imageN in landmark_dict.keys():\n",
    "             \n",
    "            name_lm = landmark_dict[imageN]\n",
    "            if name_lm == '':\n",
    "                continue\n",
    "            #print name_lm\n",
    "            if name_lm not in landmark_name_set:\n",
    "                landmark_name_set.add(name_lm)\n",
    "                name = \"http://www.columbia.edu/AIDA/DVMM/Entities/Landmark/\"+ \\\n",
    "                str(landmark_id[name_lm])+\"/\"+name_lm\n",
    "                entity = aifutils.make_entity(g, name, sys)\n",
    "                entityDic_b[name_lm] = entity\n",
    "                #print AIDA_PROGRAM_ONTOLOGY2.term('Person')\n",
    "                score =  1\n",
    "                type_assertion = aifutils.mark_type(g, \\\n",
    "                    \"http://www.columbia.edu/AIDA/DVMM/TypeAssertion/Landmark/\"+ \\\n",
    "                str(landmark_id[name_lm])+\"/\"+name_lm \\\n",
    "                    , entity, AIDA_PROGRAM_ONTOLOGY_b.term('FAC'), sys, score)\n",
    "                if 'Maidan' in name_lm:\n",
    "                    aifutils.link_to_external_kb(g, entity, \"LDC2019E43:80000020\" , sys, 1)\n",
    "                elif 'United_States_Capitol' in name_lm:\n",
    "                    aifutils.link_to_external_kb(g, entity, \"LDC2019E43:4140827\" , sys, 1)\n",
    "                \n",
    "                else:\n",
    "                    aifutils.link_to_external_kb(g, entity, VIS_ONTOLOGY_b.term(name_lm) , sys, 1)\n",
    "\n",
    "    for imageN in chi:\n",
    "        total_key.add(imageN)\n",
    "        if imageN in landmark_dict.keys():\n",
    "            #print parent\n",
    "            key = imageN\n",
    "            name_lm = landmark_dict[imageN]\n",
    "            if name_lm == '':\n",
    "                continue\n",
    "            #aifutils.mark_as_possible_cluster_member(g, \\\n",
    "            #    entity,clusterDic_b[0], 1, sys)\n",
    "            \n",
    "            # Need to change in future\n",
    "            im = Image.open(input_img_path+imageN+'.jpg')\n",
    "            width, height = im.size\n",
    "            bb2 = Bounding_Box((0,0), (width,height)) #l u r d\n",
    "            type_assertion = aifutils.mark_type(g, \\\n",
    "            \"http://www.columbia.edu/AIDA/DVMM/TypeAssertion/Landmark/RUN00010/JPG/\"+\\\n",
    "                str(key)+'/'+str(0), entityDic_b[name_lm], AIDA_PROGRAM_ONTOLOGY_b.term('FAC'), sys, 1)\n",
    "            justif = aifutils.mark_image_justification(g, [entityDic_b[name_lm], type_assertion], key, bb2, sys, 1)\n",
    "            aifutils.add_source_document_to_justification(g, justif, parent)\n",
    "            aifutils.mark_informative_justification(g, entityDic_b[name_lm], justif)\n",
    "            \n",
    "            \n",
    "                                                           \n",
    "    #=============face recognition=============\n",
    "    sys = aifutils.make_system_with_uri(g, \"http://www.columbia.edu/AIDA/DVMM/Systems/Face/FaceNet\")\n",
    "\n",
    "            \n",
    "    \n",
    "    \n",
    "    NameDetected = set()\n",
    "    NameDetected_score = {}\n",
    "    nameCount = Counter()\n",
    "    count = 0\n",
    "    c_num = 0\n",
    "    person_c_n = 0\n",
    "    #print comblineSet\n",
    "    In = 0\n",
    "    #print bb\n",
    "    featureDic = {}\n",
    "    first = 1\n",
    "    entityList = []\n",
    "    arrayList = []\n",
    "    person_label = ['/m/01g317','/m/04yx4','/m/03bt1vf','/m/01bl7v','/m/05r655','/m/04hgtk','/m/01bgsw']\n",
    "    for x, y in result.items():\n",
    "        #print x\n",
    "\n",
    "        data = x.split('/')[-1]\n",
    "        if '._' in data:\n",
    "            continue\n",
    "        data2 = data.split('_')\n",
    "        #print data2[0]\n",
    "        #print data2[1][:-4]\n",
    "        key = data2[0]\n",
    "        i = data2[1][:-4]\n",
    "        #print chi\n",
    "        #print key\n",
    "        \n",
    "        if key not in chi:\n",
    "            continue\n",
    "        if y[0].replace(' ','_') not in nameSet or nameDic[y[0].replace(' ','_')] not in p1Set or float(y[1])<0.04 or y[0].replace(' ','_') == 'Ban_Ki-moon':\n",
    "      \n",
    "            continue\n",
    "        else:\n",
    "            NameDetected.add(nameDic[y[0].replace(' ','_')])\n",
    "            score = float(y[1])+0.5\n",
    "            NameDetected_score[nameDic[y[0].replace(' ','_')]] = min(1,score)\n",
    "            \n",
    "    for x, y in result2.items():\n",
    "        #print x\n",
    "        data = x.split('/')[-2]\n",
    "        if '._' in data:\n",
    "            continue\n",
    "\n",
    "\n",
    "        data = x.split('/')[-1]\n",
    "        data2 = data.split('_')\n",
    "        key = x.split('/')[-2]\n",
    "        \n",
    " \n",
    "        if videoDic[key] not in chi:\n",
    "            continue\n",
    "            \n",
    "        if y[0].replace(' ','_') not in nameSet or nameDic[y[0].replace(' ','_')] not in p1Set or float(y[1])<0.04 or y[0].replace(' ','_') == 'Ban_Ki-moon':\n",
    "          \n",
    "            continue\n",
    "        else:    \n",
    "            NameDetected.add(nameDic[y[0].replace(' ','_')])\n",
    "            score = float(y[1])+0.5\n",
    "            NameDetected_score[nameDic[y[0].replace(' ','_')]] = min(1,score)\n",
    "            \n",
    "    for key, value in index_category.items(): #key name. value is number\n",
    "        if key not in NameDetected:\n",
    "            continue\n",
    "        key = key.replace(' ','_')\n",
    "        \n",
    "        #keu = entityDic\n",
    "        name = \"http://www.columbia.edu/AIDA/DVMM/Entities/FaceID/\"+str(value)+'/'+key\n",
    "        entity = aifutils.make_entity(g, name, sys)\n",
    "        entityDic[key] = entity\n",
    "        #print AIDA_PROGRAM_ONTOLOGY2.term('Person')\n",
    "        #score = NameDetected_score[key]\n",
    "        type_assertion = aifutils.mark_type(g, \\\n",
    "            \"http://www.columbia.edu/AIDA/DVMM/TypeAssertion/FaceID/\"\\\n",
    "            +str(value)+'/'+key, entity, AIDA_PROGRAM_ONTOLOGY2.term('PER'), sys, 1)\n",
    "\n",
    "        new_key = key.lower().replace('_',' ')\n",
    "        if new_key in name2ID.keys():\n",
    "            aifutils.link_to_external_kb(g, entity, \"LDC2019E43:\"+name2ID[new_key], sys, 1)\n",
    "            #print 'Lorelei'\n",
    "            #print parent\n",
    "        else:\n",
    "            a = 0\n",
    "            #print 'dbpedia'\n",
    "            #print parent\n",
    "            aifutils.link_to_external_kb(g, entity, VIS_ONTOLOGY2.term(key) , sys, 1)\n",
    "\n",
    "            \n",
    "    for x, y in result.items():\n",
    "        #print x\n",
    "\n",
    "        data = x.split('/')[-1]\n",
    "        if '._' in data:\n",
    "            continue\n",
    "        data2 = data.split('_')\n",
    "        #print data2[0]\n",
    "        #print data2[1][:-4]\n",
    "        key = data2[0]\n",
    "        i = data2[1][:-4]\n",
    "        #print chi\n",
    "        #print key\n",
    "        \n",
    "        if key not in chi:\n",
    "            continue\n",
    "        #print chi\n",
    "        #print key\n",
    "        In = 1\n",
    "\n",
    "        name = \"http://www.columbia.edu/AIDA/DVMM/Entities/FaceDetection/RUN00010/\"+str(key)+'/'+str(i)\n",
    "        #entityList.append(key)\n",
    "        #entityList.append(entity)\n",
    "        entity = aifutils.make_entity(g, name, sys)\n",
    "\n",
    "               \n",
    "        first_cluster = 1\n",
    "        #======================== JPG ===============\n",
    "        eid_list = []\n",
    "        \n",
    "        if key in OD_result.keys():\n",
    "            for n in range(len(OD_result[key])):\n",
    "\n",
    "                #print OD_result[key][n]['label']\n",
    "                if OD_result[key][n]['label'] in person_label:\n",
    "                    #print OD_result[key][n]['label']\n",
    "                    boxA = OD_result[key][n]['bbox']\n",
    "                    boxB = (int(bb[x][0]),int(bb[x][1]),int(bb[x][2]),int(bb[x][3]))\n",
    "                    IOA = bb_intersection_over_union(boxA, boxB)\n",
    "                    if IOA > 0.9:\n",
    "                    #left,top,right,bottom =  OD_result[key][n]['bbox']\n",
    "                    #if int(bb[x][1]) > left and int(bb[x][0]) > top and int(bb[x][3]) < right and int(bb[x][2]) < bottom:\n",
    "\n",
    "                        eid = \"http://www.columbia.edu/AIDA/DVMM/Entities/ObjectDetection/RUN00010/JPG/\"+key+\"/\"+str(n)\n",
    "                        #print entity_dic2[key]\n",
    "                        #print n\n",
    "                        if n in entity_dic2[key]:\n",
    "                        #if eid in entity_dict.keys():\n",
    "                            score = IOA\n",
    "\n",
    "                            eid_list.append(eid)\n",
    "                            if first_cluster == 1:\n",
    "\n",
    "                                first_cluster = 0\n",
    "                                clusterName = aifutils.make_cluster_with_prototype(g, \\\n",
    "                                \"http://www.columbia.edu/AIDA/DVMM/Clusters/HumanBody/RUN00010/JPG/\"\\\n",
    "                                +key+\"/\"+str(n)+\"/\"+str(person_c_n),entity, sys)\n",
    "\n",
    "                            aifutils.mark_as_possible_cluster_member(g, \\\n",
    "                                    entity_dict[eid],clusterName, score, sys)\n",
    "\n",
    "            if first_cluster == 0:\n",
    "\n",
    "                person_c_n+=1\n",
    "\n",
    "        l,t,r,d = bb[x]\n",
    "        if (r-l)*(d-t)>3600:\n",
    "            entityList.append(entity) \n",
    "            arrayList.append(y[2])\n",
    "\n",
    "        feature = {}\n",
    "        feature['columbia_vector_faceID_FaceNet'] = y[2].tolist()\n",
    "        json_data = json.dumps(feature)\n",
    "        aifutils.mark_private_data(g, entity, json_data, sys)\n",
    "        #labelrdf = VIS_ONTOLOGY.term(i_id)\n",
    "        #Dscore = value[i][7]\n",
    "        #if Dscore>1:\n",
    "        Dscore=1\n",
    "        #type_assertion = aifutils.mark_type(g, \"Columbia/DVMM/TypeAssertion/FaceRecognition/RUN00003/\"+str(i_id)+\"/\"+str(i)+\"/1\", \n",
    "        type_assertion = aifutils.mark_type(g, \\\n",
    "        \"http://www.columbia.edu/AIDA/DVMM/TypeAssertion/FaceDetection/RUN00010/JPG/\"+\\\n",
    "            str(key)+'/'+str(i), entity, AIDA_PROGRAM_ONTOLOGY2.term('PER'), sys, Dscore)\n",
    "\n",
    "        bb2 = Bounding_Box((bb[x][0], bb[x][1]), (bb[x][2], bb[x][3]))\n",
    "        \n",
    "        justif = aifutils.mark_image_justification(g, [entity, type_assertion], key, bb2, sys, 1)\n",
    "        aifutils.add_source_document_to_justification(g, justif, parent)\n",
    "        aifutils.mark_informative_justification(g, entity, justif)\n",
    "        chi_set.add(key)\n",
    "        parent_set.add(parent)\n",
    "     \n",
    "        if y[0].replace(' ','_') not in nameSet or nameDic[y[0].replace(' ','_')] not in p1Set or float(y[1])<0.04 or y[0].replace(' ','_') == 'Ban_Ki-moon':\n",
    "           \n",
    "            continue\n",
    "        else:\n",
    "            #nameCount2+=1\n",
    "            person_set.add(y[0])\n",
    "            doc_N.add(parent)\n",
    "            img_N.add(key)\n",
    "\n",
    "            score = sigmoid(float(y[1])*10)\n",
    " \n",
    "            NameDetected.add(nameDic[y[0].replace(' ','_')])\n",
    "            #print y[0]\n",
    "            entity_key = nameDic[y[0].replace(' ','_')]\n",
    "            type_assertion = aifutils.mark_type(g, \\\n",
    "            \"http://www.columbia.edu/AIDA/DVMM/TypeAssertion/FaceID/\"\\\n",
    "            +str(index_category[entity_key])+'/'+entity_key, entityDic[entity_key], AIDA_PROGRAM_ONTOLOGY2.term('PER'), sys, 1)\n",
    "\n",
    "            justif = aifutils.mark_image_justification(g, [entityDic[nameDic[y[0].replace(' ','_')]], \\\n",
    "                                                           type_assertion], key, bb2, sys, score)\n",
    "            aifutils.add_source_document_to_justification(g, justif, parent)\n",
    "            aifutils.mark_informative_justification(g, entityDic[nameDic[y[0].replace(' ','_')]], justif)\n",
    "            \n",
    "            #                                    entity, labelrdf, sys, score)\n",
    "\n",
    "            #print str(value[i][2]).replace(\"L\",'')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #========================== Video Frame ================\n",
    "    for x, y in result2.items():\n",
    "        #print x\n",
    "        data = x.split('/')[-2]\n",
    "        if '._' in data:\n",
    "            continue\n",
    "\n",
    "\n",
    "        data = x.split('/')[-1]\n",
    "        data2 = data.split('_')\n",
    "        key = x.split('/')[-2]\n",
    "        \n",
    "\n",
    "        if videoDic[key] not in chi:\n",
    "            continue\n",
    "        #print \"video\"\n",
    "        In = 1\n",
    "        i = data2[-1][:-4]\n",
    "        frame = data[:-len(data2[-1])-1]\n",
    "        frameNum = frame.split('_')[-1]\n",
    "\n",
    "        name = \"http://www.columbia.edu/AIDA/DVMM/Entities/FaceDetection/RUN00010/Keyframe/\"+\\\n",
    "        str(videoDic[key])+'_'+str(frameNum)+'/'+str(i)\n",
    "        entity = aifutils.make_entity(g, name, sys)\n",
    "\n",
    "        if str(videoDic[key])+'_'+str(frameNum) in ODF_result.keys():\n",
    "            first_cluster = 1\n",
    "\n",
    "            for n in range(len(ODF_result[str(videoDic[key])+'_'+str(frameNum)])):\n",
    "      \n",
    "                if ODF_result[str(videoDic[key])+'_'+str(frameNum)][n]['label'] in person_label:     \n",
    "\n",
    "                    boxA = ODF_result[str(videoDic[key])+'_'+str(frameNum)][n]['bbox']\n",
    "                    boxB = (int(bb_2[x][0]),int(bb_2[x][1]),int(bb_2[x][2]),int(bb_2[x][3]))\n",
    "                    IOA = bb_intersection_over_union(boxA, boxB)\n",
    "                    if IOA > 0.9:\n",
    "    \n",
    "                        eid = \"http://www.columbia.edu/AIDA/DVMM/Entities/ObjectDetection/RUN00010/Keyframe/\"+str(videoDic[key])+'_'+str(frameNum)+\"/\"+str(n)\n",
    "                        if n in entity_dic2[str(videoDic[key])+'_'+str(frameNum)]:\n",
    "                        #if eid in entity_dict.keys():\n",
    "                            score = IOA\n",
    "                            #print x\n",
    "                            #print entity_dict[eid]\n",
    "                            #print n\n",
    "\n",
    "                            if first_cluster == 1:\n",
    "\n",
    "                                first_cluster = 0\n",
    "                                clusterName = aifutils.make_cluster_with_prototype(g, \\\n",
    "                                \"http://www.columbia.edu/AIDA/DVMM/Clusters/HumanBody/RUN00010/Keyframe/\"+\\\n",
    "                                str(videoDic[key])+'_'+str(frameNum)+'/'+str(i)+'/'+\\\n",
    "                                str(person_c_n),entity, sys)\n",
    "                                #aifutils.mark_as_possible_cluster_member(g, \\\n",
    "                                #    entity,clusterName, score, sys)\n",
    "\n",
    "                            aifutils.mark_as_possible_cluster_member(g, \\\n",
    "                                    entity_dict[eid],clusterName, score, sys)\n",
    "            if first_cluster == 0:\n",
    "                person_c_n+=1\n",
    "\n",
    "        #txn.put(\"Columbia/DVMM/TypeAssertion/FaceID/RUN00003/\"+str(key)+'/'+str(i), value[i][4]);\n",
    "        #featureDic[entity] = y[2]\n",
    "        featureDic[key] = y[2]\n",
    "\n",
    "        #entityList.append(key)\n",
    "        l,t,r,d = bb_2[x]\n",
    "        if (r-l)*(d-t)>3600:\n",
    "            entityList.append(entity)\n",
    "            arrayList.append(y[2])\n",
    "        #if first == 1:\n",
    "        #    new_array = [y[2]]\n",
    "        #    first = 0\n",
    "        #else:\n",
    "        #    new_array = np.concatenate((new_array, [y[2]]), axis=0)\n",
    "        feature = {}\n",
    "        feature['columbia_vector_faceID_FaceNet'] = y[2].tolist()\n",
    "        json_data = json.dumps(feature)\n",
    "        aifutils.mark_private_data(g, entity, json_data, sys)\n",
    "        #labelrdf = VIS_ONTOLOGY.term(i_id)\n",
    "        #Dscore = value[i][7]\n",
    "        #if Dscore>1:\n",
    "        Dscore=1\n",
    "        #type_assertion = aifutils.mark_type(g, \"Columbia/DVMM/TypeAssertion/FaceRecognition/RUN00003/\"+str(i_id)+\"/\"+str(i)+\"/1\", \n",
    "        type_assertion = aifutils.mark_type(g, \"http://www.columbia.edu/AIDA/DVMM/TypeAssertion/FaceDetection/RUN00010/Keyframe/\"+\\\n",
    "            str(videoDic[key])+'_'+str(frameNum)+'/'+str(i), entity, AIDA_PROGRAM_ONTOLOGY2.term('PER'), sys, Dscore)\n",
    "            #str(videoDic[key])+'_'+str(frameNum)+'/'+str(i), entity, AIDA_PROGRAM_ONTOLOGY2.Entity, sys, Dscore)\n",
    "        #print bb[x][1]\n",
    "        bb2 = Bounding_Box((bb_2[x][0], bb_2[x][1]), (bb_2[x][2], bb_2[x][3]))\n",
    "        #aifutils.mark_image_justification(g, [entity, type_assertion], key, bb2, sys, 1)\n",
    "        justif = aifutils.mark_keyframe_video_justification(g, [entity, type_assertion], videoDic[key], \\\n",
    "                                                            str(videoDic[key])+'_'+str(frameNum), bb2, sys, 1)\n",
    "        aifutils.add_source_document_to_justification(g, justif, parent)\n",
    "        aifutils.mark_informative_justification(g, entity, justif)\n",
    "        \n",
    "        chi_set.add(key)\n",
    "        parent_set.add(parent)\n",
    "        if y[0].replace(' ','_') not in nameSet or nameDic[y[0].replace(' ','_')] not in p1Set or float(y[1])<0.04 or y[0].replace(' ','_') == 'Ban_Ki-moon':\n",
    "            continue\n",
    "        else:\n",
    "            #nameCount2+=1\n",
    "            person_set.add(y[0])\n",
    "            doc_N.add(parent)\n",
    "            img_N.add(key)\n",
    "            #if float(y[1])*10>1:\n",
    "            #    score = 1-random.random()/10\n",
    "            #else:\n",
    "            #    score = float(y[1])*10\n",
    "            score = sigmoid(float(y[1])*10)\n",
    "            #place_of_birth_in_louisville_cluster = aifutils.mark_as_possible_cluster_member(g, \\\n",
    "            #    entity,clusterDic[nameDic[y[0].replace(' ','_')]], score, sys)\n",
    "            NameDetected.add(nameDic[y[0].replace(' ','_')])\n",
    "            entity_key = nameDic[y[0].replace(' ','_')]\n",
    "            type_assertion = aifutils.mark_type(g, \\\n",
    "            \"http://www.columbia.edu/AIDA/DVMM/TypeAssertion/FaceID/\"\\\n",
    "            +str(index_category[entity_key])+'/'+entity_key, entityDic[entity_key], AIDA_PROGRAM_ONTOLOGY2.term('PER'), sys, 1)\n",
    "            justif = aifutils.mark_keyframe_video_justification(g, [entityDic[nameDic[y[0].replace(' ','_')]], type_assertion], videoDic[key], \\\n",
    "                                                            str(videoDic[key])+'_'+str(frameNum), bb2, sys, score)\n",
    "            aifutils.add_source_document_to_justification(g, justif, parent)\n",
    "            aifutils.mark_informative_justification(g, entityDic[nameDic[y[0].replace(' ','_')]], justif)\n",
    "\n",
    "\n",
    "    #dbscan_run(arrayList,entityList)\n",
    "    new_array = np.array(arrayList)\n",
    "    \n",
    "    if len(arrayList)>1 :\n",
    "\n",
    "        # Compute DBSCAN\n",
    "        #if __name__ == '__main__':\n",
    "        db = DBSCAN(eps=0.55, min_samples=2).fit(new_array)\n",
    "        core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "        core_samples_mask[db.core_sample_indices_] = True\n",
    "        labels = db.labels_\n",
    "        #print labels\n",
    "        # Number of clusters in labels, ignoring noise if present.\n",
    "        n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        #print entityList\n",
    "            #print('Estimated number of clusters: %d' % n_clusters_)\n",
    "\n",
    "        clusterNameDic = {}\n",
    "\n",
    "\n",
    "\n",
    "        firstMem = [0 for i in range(n_clusters_)]\n",
    "        firstArray = {}\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == -1:\n",
    "                continue\n",
    "            #print len(labels)\n",
    "            #print len(entityList)\n",
    "            #score = 1\n",
    "            if firstMem[labels[i]] == 0:\n",
    "                firstMem[labels[i]] = 1\n",
    "                firstArray[labels[i]] = new_array[i]\n",
    "                clusterNameDic[labels[i]] = aifutils.make_cluster_with_prototype(g, \\\n",
    "                    \"http://www.columbia.edu/AIDA/DVMM/Clusters/FaceCoreference/RUN00010/\"+\\\n",
    "                    str(labels[i]),entityList[i], sys)\n",
    "                #print entityList[a][j]\n",
    "            else:\n",
    "                dist = np.linalg.norm(firstArray[labels[i]]- new_array[i])\n",
    "                if dist>1:\n",
    "                    score = 0.001\n",
    "                else:\n",
    "                    score = 1-dist/2\n",
    "                #score = sigmoid(dist)\n",
    "                #print score\n",
    "                aifutils.mark_as_possible_cluster_member(g, \\\n",
    "                    entityList[i],clusterNameDic[labels[i]], score, sys)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    sys = aifutils.make_system_with_uri(g, \"http://www.columbia.edu/AIDA/DVMM/Systems/Face/FaceNet\")\n",
    "    for key, value in index_category.items():\n",
    "        if key not in NameDetected:\n",
    "            continue\n",
    "        key = key.replace(' ','_')\n",
    "        \n",
    "        #print name2ID[]\n",
    "        new_key = key.lower().replace('_',' ')\n",
    "        #print new_key\n",
    "        try:\n",
    "            #print RPI[parent].keys()\n",
    "            #print name2ID[new_key]\n",
    "            if name2ID[new_key] in RPI[parent].keys():\n",
    "                print (new_key)\n",
    "                #print parent\n",
    "                cluster = aifutils.make_cluster_with_prototype(g, \\\n",
    "                    \"http://www.columbia.edu/AIDA/DVMM/Clusters/NamedPersonCoreference/\"+\\\n",
    "                    str(value)+'/'+key,entityDic[key], sys)\n",
    "                score = 1 \n",
    "                #aifutils.mark_as_possible_cluster_member(g, ,cluster, score, sys)\n",
    "                for i in range(len(RPI[parent][name2ID[new_key]])):\n",
    "                    aifutils.mark_as_possible_cluster_member(g, \\\n",
    "                        RPI[parent][name2ID[new_key]][i],cluster, score, sys)\n",
    "        except KeyError:\n",
    "            a = 0\n",
    "    \n",
    "    \n",
    "    directory = 'ttl/'+outputN+'/'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    with open(directory+parent+'.ttl', 'w') as fout:\n",
    "        serialization = BytesIO()\n",
    "        # need .buffer because serialize will write bytes, not str\n",
    "        g.serialize(destination=serialization, format='turtle')\n",
    "        fout.write(serialization.getvalue().decode('utf-8'))\n",
    "\n",
    "    \n",
    "\n",
    "pool = mp.Pool(processes=40)\n",
    "\n",
    "res = pool.map(transferAIF, child.keys())\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "print (nameCount2)\n",
    "print (len(chi_set))\n",
    "print (len(parent_set))\n",
    "print (len(person_set))\n",
    "print (len(total_key))\n",
    "print (len(doc_N))\n",
    "print (len(img_N))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
