{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, RDF, URIRef\n",
    "from rdflib.namespace import SKOS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nist_ont_pref = 'https://tac.nist.gov/tracks/SM-KBP/2018/ontologies/InterchangeOntology#'\n",
    "turtle_dir = '/home/alireza/aida/hypotheses/m9_sample'\n",
    "with open(os.path.join(turtle_dir, 'kbfiles.txt'), 'r') as fin:\n",
    "    turtle_files = [os.path.join(turtle_dir, item.strip()) for item in fin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/alireza/aida/hypotheses/m9_sample/./T103/T103_Q001_H003.hypothesis.feedback.ttl',\n",
       " '/home/alireza/aida/hypotheses/m9_sample/./T103/IC00120VX.parent.ttl',\n",
       " '/home/alireza/aida/hypotheses/m9_sample/./T103/IC0011X4T.parent.ttl',\n",
       " '/home/alireza/aida/hypotheses/m9_sample/./T103/IC00120UN.parent.ttl',\n",
       " '/home/alireza/aida/hypotheses/m9_sample/./T103/IC00150IB.parent.ttl',\n",
       " '/home/alireza/aida/hypotheses/m9_sample/./T103/IC0011YF6.parent.ttl',\n",
       " '/home/alireza/aida/hypotheses/m9_sample/./T103/T103_Q001_H006.partial.ttl',\n",
       " '/home/alireza/aida/hypotheses/m9_sample/./T103/IC0011XCW.parent.ttl',\n",
       " '/home/alireza/aida/hypotheses/m9_sample/./T103/IC0018KDK.parent.ttl',\n",
       " '/home/alireza/aida/hypotheses/m9_sample/./T103/T103.kb.ttl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turtle_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(turtle_path):\n",
    "    entity2mention = {}\n",
    "    \n",
    "    entity_ = URIRef(nist_ont_pref+'Entity')\n",
    "    hasName_ = URIRef(nist_ont_pref+'hasName')\n",
    "    sys_ = URIRef(nist_ont_pref+'system')\n",
    "    justified_by_ = URIRef(nist_ont_pref+'justifiedBy')\n",
    "    \n",
    "    turtle_content = open(turtle_path).read()\n",
    "    graph = Graph()\n",
    "    graph.parse(data=turtle_content, format='n3')\n",
    "    entities = graph.subjects(predicate=RDF.type,object=entity_)\n",
    "    for entity in entities:\n",
    "        entity_id = entity.toPython()\n",
    "        temp = list(graph.objects(predicate=hasName_,subject=entity))\n",
    "        entity_name = temp[0].toPython() if len(temp) > 0 else None\n",
    "        temp = list(graph.objects(predicate=sys_,subject=entity))\n",
    "        en_sys_rdf = temp[0] if len(temp) > 0 else None\n",
    "        temp = list(graph.subjects(predicate=RDF.subject,object=entity))\n",
    "        en_asser_node = temp[0] if len(temp) > 0 else None\n",
    "        if en_asser_node != None:\n",
    "            temp = list(graph.objects(subject = en_asser_node,predicate=RDF.object))\n",
    "            en_type_rdf = temp[0] if len(temp) > 0 else None\n",
    "        else:\n",
    "            en_type_rdf = None\n",
    "\n",
    "        entity2mention[entity_id] = {'mentions': {},\n",
    "                                     'name': entity_name,\n",
    "                                     'type_rdf': en_type_rdf,\n",
    "                                     'sys_rdf': en_sys_rdf}\n",
    "\n",
    "        just_by = graph.objects(predicate=justified_by_,subject=en_asser_node)        \n",
    "        for just in just_by:\n",
    "            mention_id = just.toPython()\n",
    "            temp = list(graph.objects(subject=just, predicate=SKOS.prefLabel))\n",
    "            mention_name = temp[0].toPython() if len(temp) > 0 else None\n",
    "            source = list(graph.objects(subject=just,\n",
    "                            predicate=URIRef(nist_ont_pref+'source')))[0].toPython()\n",
    "            \n",
    "            mention_type = list(graph.objects(predicate=RDF.type,subject=just))[0]\n",
    "            mtype = mention_type.split('#')[-1]\n",
    "            \n",
    "            pv_data_rdf = list(graph.objects(subject=just,\n",
    "                            predicate=URIRef(nist_ont_pref+'privateData')))\n",
    "            pv_data_dict = {}\n",
    "            for pv_rdf in pv_data_rdf:\n",
    "                dict_str=list(graph.objects(subject=pv_rdf,\n",
    "                                predicate=URIRef(nist_ont_pref+'jsonContent')))[0].toPython()\n",
    "                pv_data_dict.update(json.loads(dict_str))\n",
    "                    \n",
    "            entity2mention[entity_id]['mentions'][mention_id] = {\n",
    "                'type': mention_type,\n",
    "                'name': mention_name,\n",
    "                'source': source,\n",
    "                'private_data': pv_data_dict,\n",
    "            }\n",
    "            \n",
    "            if mtype == 'TextJustification':\n",
    "                off_beg = list(graph.objects(subject=just,\n",
    "                                predicate=URIRef(nist_ont_pref+'startOffset')))[0].toPython()\n",
    "                off_end = list(graph.objects(subject=just,\n",
    "                                predicate=URIRef(nist_ont_pref+'endOffsetInclusive')))[0].toPython()\n",
    "                entity2mention[entity_id]['mentions'][mention_id]['offset'] = (off_beg, off_end)\n",
    "            elif mtype == 'ImageJustification':\n",
    "                bbox = list(graph.objects(subject=just,\n",
    "                            predicate=URIRef(nist_ont_pref+'boundingBox')))[0]\n",
    "                bbox_coords = (\n",
    "                    list(graph.objects(subject=bbox, predicate=URIRef(nist_ont_pref+'boundingBoxUpperLeftX')))[0].toPython(),\n",
    "                    list(graph.objects(subject=bbox, predicate=URIRef(nist_ont_pref+'boundingBoxUpperLeftY')))[0].toPython(),\n",
    "                    list(graph.objects(subject=bbox, predicate=URIRef(nist_ont_pref+'boundingBoxLowerRightX')))[0].toPython(),\n",
    "                    list(graph.objects(subject=bbox, predicate=URIRef(nist_ont_pref+'boundingBoxLowerRightY')))[0].toPython(),\n",
    "                )\n",
    "                entity2mention[entity_id]['mentions'][mention_id]['bbox'] = bbox_coords\n",
    "            elif mtype == 'KeyFrameVideoJustification':\n",
    "                bbox = list(graph.objects(subject=just,\n",
    "                            predicate=URIRef(nist_ont_pref+'boundingBox')))[0]\n",
    "                bbox_coords = (\n",
    "                    list(graph.objects(subject=bbox, predicate=URIRef(nist_ont_pref+'boundingBoxUpperLeftX')))[0].toPython(),\n",
    "                    list(graph.objects(subject=bbox, predicate=URIRef(nist_ont_pref+'boundingBoxUpperLeftY')))[0].toPython(),\n",
    "                    list(graph.objects(subject=bbox, predicate=URIRef(nist_ont_pref+'boundingBoxLowerRightX')))[0].toPython(),\n",
    "                    list(graph.objects(subject=bbox, predicate=URIRef(nist_ont_pref+'boundingBoxLowerRightY')))[0].toPython(),\n",
    "                )\n",
    "                keyframe = list(graph.objects(subject=just,\n",
    "                                predicate=URIRef(nist_ont_pref+'keyFrame')))[0].toPython()\n",
    "                entity2mention[entity_id]['mentions'][mention_id]['bbox'] = bbox_coords\n",
    "                entity2mention[entity_id]['mentions'][mention_id]['keyframe_id'] = keyframe\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "                \n",
    "    return entity2mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = {}\n",
    "for turtle_path in turtle_files:\n",
    "    entities.update(get_entities(turtle_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../temp/hypo_sample_1.pkl', 'wb') as fout:\n",
    "    pickle.dump(entities, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../temp/hypo_sample_1.pkl', 'rb') as fin:\n",
    "    entities = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_hypo = {}\n",
    "for eid in entities:\n",
    "    for mention in entities[eid]['mentions'].values():\n",
    "        if mention['type'].split('#')[-1] == 'ImageJustification' and mention['source'] != None:\n",
    "            if mention['source'] not in image_hypo:\n",
    "                image_hypo[mention['source']] = []\n",
    "            image_hypo[mention['source']].append((eid, entities[eid]['type_rdf']))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_hypo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyframe_hypo = {}\n",
    "for eid in entities:\n",
    "    for mention in entities[eid]['mentions'].values():\n",
    "        if mention['type'].split('#')[-1] == 'KeyFrameVideoJustification' and mention['source'] != None:\n",
    "            if mention['source'] not in image_hypo:\n",
    "                keyframe_hypo[mention['source']] = []\n",
    "            keyframe_hypo[mention['source']].append((eid, entities[eid]['type_rdf']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keyframe_hypo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../temp/hypo_sample_1_leaf2ents.pkl', 'wb') as fout:\n",
    "    pickle.dump((image_hypo, keyframe_hypo), fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3 for AIDA",
   "language": "python",
   "name": "aida"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
